---
title: "Simulated data documentation"
author: "Steve and Jonathan"
date: ' `r as.Date(Sys.time())` '
output:
  html_document:
    fig_caption: yes
    toc: yes
    toc_depth: 4
    toc_float: yes
---


```{r setup, include=FALSE, cache=FALSE}
knitr::opts_chunk$set(echo = FALSE
	, warning = FALSE
	, message = FALSE
	, fig.width = 10
	, fig.height = 10
	, fig.align = "center"
	, results = "asis")
options(width = 12)

library(ggplot2)
theme_set(theme_bw() +
	theme(panel.spacing=grid::unit(0,"lines")))

library(ggpubr)
library(dplyr)
library(tidyr)
library(scales)
library(DT)

source("../funs/ggplot_theme.R")

load("switchSummary.rda")
load("switchPredEffects.rda")
load("switchTidy.rda")
```

```{r functions, include=FALSE}
# A function for captioning and referencing images
fig <- local({
    i <- 0
    ref <- list()
    list(
        cap=function(refName, text) {
            i <<- i + 1
            ref[[refName]] <<- i
            paste("Figure ", i, ": ", text, sep="")
        },
        ref=function(refName) {
            ref[[refName]]
        })
})
```

In this task, we simulate data for the three WASH services using two approaches, namely:
	
- Latent variable approach
- Matrix based approach (known covariances and correlations)

The details are discussed in the sections below.


## Latent variable approach

The main idea is to simulate both measured and unmeasured covariates from a given distribution with know parameters. For simplicity, we consider only one measured covariate $(x)$ and one unmeasured covariate $(x')$.

We assume that the availability of services at time $t$ depends on availability at time $t-1$ and simulate the two covariates as a first-order autoregressive, AR(1), process:

\[
x_{ht} = \overline{x}_{ht} + \phi x_{ht-1} + \epsilon_{ht}
\]

and

\[
x'_{ht} = \overline{x}'_{ht} + \phi' x'_{ht-1} + \epsilon_{ht}
\]

Where:

\[
|\phi|, |\phi'| < 1\\ 
\epsilon_{ht} \sim \mathit{N}(0, \sigma^2)\\
\overline{x}_{ht} \sim \mathit{N}(0, \sigma^2_{Asympt})\\
\overline{x}'_{ht} \sim \mathit{N}(0, \sigma^2_{Asympt})\\
\sigma^2_{Asympt} = \frac{\sigma^2}{1 - \phi^2}
\]

- $\phi$ and $\sigma^2_{Asympt}$ are the slope defining the autocorrelation at lag 1 and the theoretical variance of the AR(1) process, respectively.
- $x_{ht}$ and $x'_{ht}$ are the measured and unmeasured covariates for household $h$ at time $t$.

Let $\beta'_{1}$ and $\beta_{1}$ be the effect sizes of unmeasured and measured covariates defined above. Define linear predictor for a given service for household $h$ at time $t$ as

\[
\eta_{ht} = \beta'_{1}x'_{ht} + \beta_{1}x_{ht} + \epsilon_{h} 
\]

- $\epsilon_{h}$ are the household random effects such that

\[
\epsilon_{h} \sim \mathit{N}(0, \sigma)
\]


The household services for the time period $t + 1$ are generated using probabilities calculated from odds based on $\eta$. We can do this either mechanistically, thinking explicitly about switching, or by a simpler, statistical method based on calculations from the mechanistic method.

- **mechanistic way**
	- We assume that η is always positively correlated with having the service. Therefore the probability of gaining the service will be positively affected by η, and the probability of losing the service will be negatively affected by η.
	- If a household has service (i.e., $y_{hts} = 1$), we thus say that the log odds of losing it in the next year are $\mu_{hts} = \beta_{lose} - \eta_{hts}$. 
	- Conversely, if $y_{hts} = 0$, the log odds of gaining service is $\mu_{hts} = \beta_{\textrm{gain}} + \eta_{hts}$ 

We use this mechanistic parameterization for choosing parameters.

- **simplified (or statistical) way**

	- Both of the above routes can be summarized in a more convenient form: The log odds of household $h$ at time $t+1$ having service $s$ is:
\[
\mu_{ht+1, s} = \eta_{ht+1, s} + \beta_{gain} + \beta_{add}\mathbf{I}(y_{ht,s} = 1),\\
\mbox{where }\beta_{add} = -(\beta_{gain} + \beta_{lose}).
\]

We use this simpler parameterization for simulation and modeling. 

Once μ is known, we calculate the probability of service as:
\[
\pi_{hts} = \frac{1}{1 + \exp{(-\mu_{hts})}}
\]
	- $\mathbf{I}(y_{hts})$, $t = 0$ is based on random choice of $\mu_{hts}$ at $t=0$

We use this probability to pick values of $y_{hts}$

We simulated observed values for two services $(s = \{1,2\})$ for $1000$ households running for $50$ years and excluded the first $20$ years from the analysis (to take care of stationarity of the AR(1) process).

### Fitting method

Two approaches were used to fit the model:

- **Separate models**: Fit two separate models for each of the services and compare the estimates with the true values. Results from these models are not shown in this writeup.
- **Joint models**: Fit a multivariate mixed model for binary outcomes in `glmer` using method described by Ben Bolker (see [here](https://mac-theobio.github.io/QMEE/MultivariateMixed.html)). We can as well use Bayesian fitting interfaces but these might be very slow especially when comparing across multiple simulations. 

#### Model

We fit an intercept only multivariate random effect model with two binary variable responses which indicate whether or not a given household has improved services in a particular year. In what we term as _stepback_ method, we restructure the data and use include status (0/1) in the previous year to predict the service status in the current year. In particular, the fixed terms are availability of the service in the previous year and wealth index while the random term has a correlated, time-independent variation among the households

\[
logit(p(y_{hts} = 1)) = \beta_{0,hts} + \beta_{1,s} y_{ht-1,s} + \beta_{2,s} x\\
\beta_{0,hts} = \beta_0 + \alpha_{0,hts} \\
\alpha_{0,hts} \sim \mathit{N}(0, \sigma^2_s).
\]

Where: 

 - $\beta_{0, hts}$ is the baseline log odds of households having service  
 - $\beta_{1,s}$ is the overall effect size of improved service in the previous year on status of service in the current year (log odds of having service in the current year) 
 - $\beta_{2,s}$ is the overall effect size of household income (measure covariate, x) on the status of service  
 - $\alpha_{0,hts}$ captures the offset of household log odds of having service from the overall baseline (mean) 

 ### Results 



 The parameters were estimated from a multivariate model. 

 #### Fixed effects 

 Figures below compares true parameter values (red dots) against the estimates for $1$ simulation.  

 <!-- Figure 1 shows results for service 1 while Figure 2 shows results for service 2.  -->
 <!--   -->
 <!-- ```{R fig.cap=fig$cap("", "Service 1"), fig.align="center"}  -->
 <!-- #print(y1Beta_plot)  -->
 <!-- ```  -->
 <!--   -->
 <!-- ```{R fig.cap=fig$cap("", "Service 2"), fig.align="center"}  -->
 <!-- print(y2Beta_plot)  -->
 <!-- ```  -->


 #### Single model (y1) 

 ```{R} 
 ### Reformat betas_df 
 dd <- (betas_df 
 	%>% mutate(parameter = ifelse(grepl("\\_M", coefs2), "xm" 
 		, ifelse(grepl("gain", coefs2), "b_gain",  
 			ifelse(grepl("add", coefs2), "b_add", "b_lose")) 
 		) 
 		, term = gsub("\\_.*", "", coefs2) 
 	) 
 	%>% filter(term=="y1" & !grepl("lose", parameter)) 
 ) 
 ``` 

 ```{R fig.height = 5, fig.width = 5} 
 estimates_df <- (extract_coefs_y1 
 	%>% filter(effect == "fixed") 
 ) 
 parameters <- pull(estimates_df, parameter) %>% unique() 
 estimates_df <- (estimates_df 
 	%>% mutate(parameter = factor(parameter, levels = parameters, labels = parameters)) 
 ) 

 pos <- ggstance::position_dodgev(height=0.5) 

 print(ggplot(estimates_df, aes(x = estimate, y = parameter)) 
 	+ geom_point(position = pos) 
 	+ ggstance::geom_linerangeh(aes(xmin = conf.low, xmax = conf.high), position = pos) 
 	+ geom_point(data = dd, aes(x=betas, y = parameter), colour = "red") 
 	+ labs(x = "Estimate" 
 		, y = "" 
 	) 
 #	+ facet_wrap(~parameter, scale = "free", ncol = 1) 
 #	+ facet_theme 
 	+ theme(legend.position = "bottom") 
 ) 

 ``` 

 #### Joint model 

 ```{R fig.height = 12} 
 ### Reformat betas_df 
 betas_df2 <- (betas_df 
 	%>% mutate(parameter = ifelse(grepl("\\_M", coefs2), "xm" 
 		, ifelse(grepl("gain", coefs2), "b_gain",  
 			ifelse(grepl("add", coefs2), "b_add", "b_lose")) 
 		) 
 		, term = gsub("\\_.*", "", coefs2) 
 	) 
 	%>% filter(!grepl("lose", parameter)) 
 ) 


 estimates_df <- (extract_coefs_df 
 	%>% filter(effect == "fixed") 
 ) 
 parameters <- pull(estimates_df, parameter) %>% unique() 
 estimates_df <- (estimates_df 
 	%>% mutate(parameter = factor(parameter, levels = parameters, labels = parameters)) 
 ) 

 pos <- ggstance::position_dodgev(height=0.5) 

 print(ggplot(estimates_df, aes(x = estimate, y = term)) 
 	+ geom_point(position = pos) 
 	+ ggstance::geom_linerangeh(aes(xmin = conf.low, xmax = conf.high), position = pos) 
 	+ geom_point(data = betas_df2, aes(x=betas, y = term), colour = "red") 
 	+ labs(x = "Estimate" 
 		, y = "" 
 	) 
 	+ facet_wrap(~parameter, scale = "free", ncol = 1) 
 	+ facet_theme 
 	+ theme(legend.position = "bottom") 
 ) 
 ``` 


 ### Effect plots 

 **True values table** 

 ```{R} 
 dd <- (betas_df 
 	%>% mutate(var = ifelse(grepl("\\_M", coefs2), "xm" 
 		, ifelse(grepl("gain", coefs2), "b_gain", ifelse(grepl("add", coefs2), "b_add", "b_lose"))) 
 		, term = gsub("\\_.*", "", coefs2) 
 		, probs = round(probs, 3) 
 	) 
 	%>% select(term, var, betas, probs) 
 ) 
 datatable(dd, rownames = FALSE) 
 ``` 


 ```{R fig.height = 5, fig.width = 5} 
 print(service_plot) 
 ``` 

 ```{R fig.height = 6, fig.width = 8} 
 print(num_plots[[2]]) 
 ``` 

 ```{R fig.height = 5, fig.width = 5} 
 print(num_plots[[1]]) 
 ``` 
 <!-- #### Checkplots  -->
 <!--   -->
 <!-- Steve: JD any reference or more description?  -->
 <!--   -->
 <!-- Basically used to check how good our estimates are. We expect uniformly distributed `p-values` (piano plot?)  -->
 <!--   -->
 <!-- ```{R fig.cap=fig$cap("", "Service 1 piano plots"), fig.align="center"}  -->
 <!-- ggarrange(checkPlot_list[[1]] + labs(x = " ")  -->
 <!--    , checkPlot_list[[3]] + rremove("ylab") + labs(x = "p-value")  -->
 <!--    , checkPlot_list[[5]] + rremove("ylab") + labs(x = " ")  -->
 <!--    , common.legend = TRUE  -->
 <!--    , legend = "none"  -->
 <!--    , ncol = 3  -->
 <!-- )  -->
 <!-- ```  -->
 <!--   -->
 <!-- ```{R fig.cap=fig$cap("", "Service 2 piano plots"), fig.align="center"}  -->
 <!-- ggarrange(checkPlot_list[[2]] + labs(x = " ")  -->
 <!--    , checkPlot_list[[4]] + rremove("ylab") + labs(x = "p-value")  -->
 <!--    , checkPlot_list[[6]] + rremove("ylab") + labs(x = " ")  -->
 <!--    , common.legend = TRUE  -->
 <!--    , legend = "none"  -->
 <!--    , ncol = 3  -->
 <!-- )  -->
 <!-- ```  -->

