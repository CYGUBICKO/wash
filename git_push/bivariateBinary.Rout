
R version 3.5.1 (2018-07-02) -- "Feather Spray"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #### ---- Project: APHRC Wash Data ----
> #### ---- Task: Simulation ----
> #### ---- Fit bivariate models (Binary) ----
> #### ---- By: Steve and Jonathan ----
> #### ---- Date: 2019 May 28 (Tue) ----
> 
> library(dplyr)
> library(tidyr)
> library(tibble)
> library(ggplot2)
> library(brms)
> 
> options(dplyr.width = Inf)
> 
> theme_set(theme_bw() + theme(panel.spacing=grid::unit(0,"lines")))
> 
> load("simulatemvn.rda")
> set.seed(7777)
> 
> # Objects in
> # * sim_dflist
> # * betas_df
> # * betas
> # * x
> 
> nsims <- length(sim_dflist)
> 
> get_prior(y1bin ~ 0 + intercept + x + (1|id)
+ 	, data = sim_dflist[[1]]
+ 	, family = bernoulli
+ )
                prior class      coef group resp dpar nlpar bound
1                         b                                      
2                         b intercept                            
3                         b         x                            
4 student_t(3, 0, 10)    sd                                      
5                        sd              id                      
6                        sd Intercept    id                      
> 
> report <- 1 # Index within nsims to save for summary
> 
> priors <- c(prior(normal(0, 1), class = b)
+ 	, prior(normal(0, 1), class = b, coef = x)
+ 	, prior(normal(0, 1), class = b, coef = intercept)
+ 	, prior(inv_gamma(3, 1), class = sd)
+ )
> 
> y1model_list <- list()
> y1coef_list <- list()
> # y1
> for (s in 1:nsims){
+    df <- (sim_dflist[[s]]
+       %>% data.frame()
+    )
+ 	model <- brm(y1bin ~ 0 + intercept + x + (1|id)
+ 			, data = df
+ 			, family = bernoulli 
+ 			, cores = 4
+ 			, warmup = 500
+ 			, iter = 1e4
+ 			, seed = 7777
+ 			, prior = priors
+ 			, refresh = 0
+ 			, open_progress = FALSE
+ 	)
+ 	if (s <= report){
+ 		y1model_list[[s]] <- model # Model to store
+ 	}
+ 	y1coef_list[[s]] <- fixef(model)[, "Estimate"]
+ }
> y1coef_df <- Reduce(rbind, y1coef_list) %>% as_tibble()
> 
> #y2
> y2model_list <- list()
> y2coef_list <- list()
> for (s in 1:nsims){
+    df <- (sim_dflist[[s]]
+       %>% data.frame()
+    )
+ 	model <- brm(y2bin ~ 0 + intercept + x + (1|id)
+ 			, data = df
+ 			, family = bernoulli 
+ 			, cores = 4
+ 			, warmup = 500
+ 			, iter = 1e4
+ 			, seed = 7777
+ 			, prior = priors
+ 			, refresh = 0
+ 			, open_progress = FALSE
+ 	)
+ 	if (s <= report){
+ 		y2model_list[[s]] <- model # Model to store
+ 	}
+ 	y2coef_list[[s]] <- fixef(model)[, "Estimate"]
+ }
> y2coef_df <- Reduce(rbind, y2coef_list) %>% as_tibble()
> 
> #y3
> y3model_list <- list()
> y3coef_list <- list()
> for (s in 1:nsims){
+    df <- (sim_dflist[[s]]
+       %>% data.frame()
+    )
+ 	model <- brm(y3bin ~ 0 + intercept + x + (1|id)
+ 			, data = df
+ 			, family = bernoulli 
+ 			, cores = 4
+ 			, warmup = 1000
+ 			, iter = 2e4
+ 			, seed = 7777
+ 			, prior = priors
+ 			, refresh = 0
+ 			, open_progress = FALSE
+ 	)
+ 	if (s <= report){
+ 		y3model_list[[s]] <- model # Model to store
+ 	}
+ 	y3coef_list[[s]] <- fixef(model)[, "Estimate"]
+ }
> y3coef_df <- Reduce(rbind, y3coef_list) %>% as_tibble()
> 
> bivmodel_list <- list(y1model = y1model_list
+ 	, y2model = y2model_list
+ 	, y3model = y3model_list
+ )
> bivcoef_list <- list(y1coef = y1coef_list
+ 	, y2coef = y2coef_list
+ 	, y3coef = y3coef_list
+ )
> 
> # Print summaries
> for(i in 1:length(bivmodel_list)){
+ 	print(bivmodel_list[[i]][[1]])
+ }
 Family: bernoulli 
  Links: mu = logit 
Formula: y1bin ~ 0 + intercept + x + (1 | id) 
   Data: df (Number of observations: 2000) 
Samples: 4 chains, each with iter = 10000; warmup = 500; thin = 1;
         total post-warmup samples = 38000

Group-Level Effects: 
~id (Number of levels: 2000) 
              Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
sd(Intercept)     0.70      0.81     0.14     3.20        124 1.02

Population-Level Effects: 
          Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
intercept     0.33      0.12     0.21     0.66        148 1.02
x             0.48      0.15     0.34     0.94        137 1.02

Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
is a crude measure of effective sample size, and Rhat is the potential 
scale reduction factor on split chains (at convergence, Rhat = 1).
 Family: bernoulli 
  Links: mu = logit 
Formula: y2bin ~ 0 + intercept + x + (1 | id) 
   Data: df (Number of observations: 2000) 
Samples: 4 chains, each with iter = 10000; warmup = 500; thin = 1;
         total post-warmup samples = 38000

Group-Level Effects: 
~id (Number of levels: 2000) 
              Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
sd(Intercept)     0.57      0.46     0.14     2.01         60 1.08

Population-Level Effects: 
          Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
intercept     0.32      0.07     0.21     0.50        114 1.04
x             0.86      0.13     0.71     1.24         69 1.07

Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
is a crude measure of effective sample size, and Rhat is the potential 
scale reduction factor on split chains (at convergence, Rhat = 1).
 Family: bernoulli 
  Links: mu = logit 
Formula: y3bin ~ 0 + intercept + x + (1 | id) 
   Data: df (Number of observations: 2000) 
Samples: 4 chains, each with iter = 20000; warmup = 1000; thin = 1;
         total post-warmup samples = 76000

Group-Level Effects: 
~id (Number of levels: 2000) 
              Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
sd(Intercept)     0.54      0.44     0.14     1.80        551 1.01

Population-Level Effects: 
          Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
intercept     0.33      0.07     0.23     0.50       1082 1.00
x             0.48      0.08     0.37     0.69        704 1.00

Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
is a crude measure of effective sample size, and Rhat is the potential 
scale reduction factor on split chains (at convergence, Rhat = 1).
> 
> save(file = "bivariateBinary.rda"
+ 	, bivmodel_list
+ 	, bivcoef_list
+ 	, betas_df
+ 	, betas
+ )
> 
> 
