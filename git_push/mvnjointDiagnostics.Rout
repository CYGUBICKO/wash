
R version 3.5.1 (2018-07-02) -- "Feather Spray"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #### ---- Project: APHRC Wash Data ----
> #### ---- Task: Simulation ----
> #### ---- Continous outcome simulation plots ----
> #### ---- By: Steve and Jonathan ----
> #### ---- Date: 2019 May 30 (Thu) ----
> 
> library(data.table)
> library(dplyr)
> library(tidyr)
> library(tibble)
> library(ggplot2)
> library(brms)
> 
> theme_set(theme_bw() + theme(panel.spacing=grid::unit(0,"lines")))
> 
> load("mvnjointModel.rda")
> 
> # Incoming objects:
> # * brmsmodel_list - glmer fits per simulation
> # * brmscoef_df - fixed effect coef per simulation
> # * betas_df & betas - initial beta values for simulations
> # * predictors  
> 
> # Clean betas_df
> # Align Beta df with the estimates
> betas_df <- (betas_df
+    %>% mutate(coef_clean = coef
+ 		, coef_clean = ifelse(grepl("0$", coef_clean), paste0("b_y", substr(n, 1, 1), "_intercept")
+          , ifelse(grepl("x:y[1-9]", coef_clean), paste0("b_y", substr(n, 1, 1), "_x")
+             , ifelse(grepl("_sd", coef_clean), paste0("sigma_y", n)
+             	, ifelse(grepl("^cor_", coef_clean), paste0("rescor__y", substr(n, 1, 1), "__y", substr(n, 2, 2))
+ 						, coef_clean
+ 					)
+ 				)
+          )
+       )
+    )
+ )
> brmsmodel <- brmsmodel_list[[1]]
> 
> summary(brmsmodel)
 Family: MV(gaussian, gaussian, gaussian) 
  Links: mu = identity; sigma = identity
         mu = identity; sigma = identity
         mu = identity; sigma = identity 
Formula: y1 ~ 0 + intercept + x 
         y2 ~ 0 + intercept + x 
         y3 ~ 0 + intercept + x 
   Data: df (Number of observations: 1000) 
Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup samples = 4000

Population-Level Effects: 
             Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
y1_intercept     0.30      0.02     0.26     0.34       7015 1.00
y1_x             0.40      0.02     0.36     0.44       6516 1.00
y2_intercept     0.29      0.02     0.26     0.33       6380 1.00
y2_x             0.79      0.02     0.76     0.82       6457 1.00
y3_intercept     0.38      0.02     0.34     0.43       5251 1.00
y3_x             0.48      0.02     0.44     0.52       5577 1.00

Family Specific Parameters: 
         Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
sigma_y1     0.61      0.01     0.58     0.64       8198 1.00
sigma_y2     0.50      0.01     0.48     0.53       6664 1.00
sigma_y3     0.70      0.02     0.67     0.73       5492 1.00

Residual Correlations: 
              Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
rescor(y1,y2)     0.18      0.03     0.12     0.24       4704 1.00
rescor(y1,y3)     0.30      0.03     0.25     0.36       5008 1.00
rescor(y2,y3)     0.50      0.02     0.45     0.55       5607 1.00

Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
is a crude measure of effective sample size, and Rhat is the potential 
scale reduction factor on split chains (at convergence, Rhat = 1).
> 
> print(betas_df)
       coef betas  n     coef_clean
1  cor_y1y2   0.2 12 rescor__y1__y2
2  cor_y1y3   0.3 13 rescor__y1__y3
3  cor_y2y3   0.5 23 rescor__y2__y3
4     x:y10   0.3 10 b_y1_intercept
5     x:y11   0.4 11         b_y1_x
6     y1_sd   0.6  1       sigma_y1
7     x:y20   0.3 20 b_y2_intercept
8     x:y21   0.8 21         b_y2_x
9     y2_sd   0.5  2       sigma_y2
10    x:y30   0.4 30 b_y3_intercept
11    x:y31   0.5 31         b_y3_x
12    y3_sd   0.7  3       sigma_y3
> 
> print(vcov(brmsmodel))
              y1_intercept          y1_x  y2_intercept          y2_x
y1_intercept  3.956478e-04 -4.871845e-05  7.130103e-05  5.820986e-06
y1_x         -4.871845e-05  3.639269e-04 -1.621117e-05  4.852757e-05
y2_intercept  7.130103e-05 -1.621117e-05  2.583017e-04 -1.521546e-05
y2_x          5.820986e-06  4.852757e-05 -1.521546e-05  2.474651e-04
y3_intercept  1.468762e-04 -2.338764e-05  1.828421e-04 -3.537579e-06
y3_x         -7.730692e-06  1.388461e-04 -1.209988e-05  1.729431e-04
              y3_intercept          y3_x
y1_intercept  1.468762e-04 -7.730692e-06
y1_x         -2.338764e-05  1.388461e-04
y2_intercept  1.828421e-04 -1.209988e-05
y2_x         -3.537579e-06  1.729431e-04
y3_intercept  5.134253e-04 -3.229382e-05
y3_x         -3.229382e-05  4.820675e-04
> 
> # Coefficient plots
> print(stanplot(brmsmodel) 
+ 	+ geom_point(data = betas_df, aes(x = betas, y = coef_clean), colour = "red")
+ )
> 
> # Zoom in
> print(stanplot(brmsmodel, type = "dens") 
+ 	+ geom_vline(data = betas_df 
+ 		%>% setnames(c("coef_clean", "betas"), c("Parameter", "Value"))
+ 		, aes(xintercept = Value)
+ 		, linetype = "dashed"
+ 		, colour = "red"
+ 	)
+    + facet_wrap(~Parameter, scales = "free", ncol = 3)
+ 	+ theme(strip.text.x = element_text(size = 6))
+ )
> 
> # Trace plots
> plot(brmsmodel)
> 
> # Marginal effect of predictors
> plot(marginal_effects(brmsmodel, "x", resp = "y1"), points = TRUE, rug = FALSE)
> plot(marginal_effects(brmsmodel, "x", resp = "y2"), points = TRUE, rug = FALSE)
> plot(marginal_effects(brmsmodel, "x", resp = "y3"), points = TRUE, rug = FALSE)
> 
